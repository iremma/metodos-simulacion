\documentclass[a4paper,12pt]{article} 
% Paquetes......................................................................
\usepackage{amsmath, amssymb, amsfonts, latexsym}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{palatino}
\usepackage[full]{textcomp}
\usepackage{hyperref}
\usepackage{eurosym}
\usepackage[makeroom]{cancel}
\usepackage{array}
\usepackage{pdfpages}
\usepackage{float} % para que las figuras no floten
\usepackage{subcaption}
\usepackage{soul}

\textheight = 24 cm
\textwidth = 17 cm

\renewcommand{\arraystretch}{1.25}
\renewcommand{\contentsname}{Contenidos}


% INICIO DEL DOCUMENTO --------------------------------------------------------
\begin{document}
	
	\setlength{\parindent}{0.5cm}
	\setlength{\voffset}{-2cm}
	\setlength{\hoffset}{-2cm}
	
	
	\input{./include/portada.tex}
	
	\tableofcontents
	
\newpage
	\section{Generación de números y variables aleatorias}
	
	\subsection{Enunciado}
	
	Describir el método \textit{Monty Phyton} para la distribución normal y compararlo con otros métodos para la generación de valores de la normal.
	
	\subsection{El método Monty Python}
	
	El objetivo del método Monty Python es lograr generar números aleatorios cuya frecuencia se aproxime a aquella de una distribución normal. Para ello, emplea la similitud entre la expresión de la función de densidad de la distribución normal y una sigmoide decreciente, así como se aprovecha del bajo coste computacional de la generación de números aleatorios en un rectángulo.
	$$ N(0,1) \sim f(x) = \dfrac{1}{\sqrt{2\pi}} \cdot e^{-x^2/2} $$
	
	Tomando $x>0$, se traza un rectángulo de base $b$ y altura $1/b$ sobre la sigmoide. Con un giro de $\pi$ radianes y un desplazamiento sobre la región exterior al rectángulo se pretende representar la mayor superficie posible de la sigmoide en el interior del rectángulo de área $1$. En las imágenes siguientes, podemos observar el procedimiento descrito tomando un $b=2.29$.
	\vspace{-1mm}
	\begin{figure}[H]
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=\textwidth]{include/sigmoid_w_square.png}
			\caption{Sigmoide con el rectángulo de base $b$. \cite{monty-python}}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=\textwidth]{include/rotating_sigmoid.png}
			\caption{Giro y desplazamiento gráficamente. \cite{monty-python}}
		\end{subfigure}
	\end{figure}
	
	Una vez descrito el área bajo la función de densidad en el interior del rectángulo, todo número aleatorio generado en ese rectángulo pertenecerá a las regiones $F$, $G$, $H$ o a la región comprendida entre $G$ y $H$ correspondiente a la cola de la sigmoide. La probabilidad de obtener un número en la cola es de un $0.022$ \cite{monty-python}.
	
	Siendo $(x,y)$ el valor aleatorio generado, $(x',y')$ será su valor correspondiente en la sigmoide.
	$$
	(x',y') = 
	\begin{cases}
		(x,y) \quad \text{si} \quad x\in F \text{ ó } G \\
		(b-x,2/b-y) \quad \text{si} \quad x \in H
	\end{cases}
	$$  
	
	Si el valor aleatorio generado no pertenece a $F$, $G$ ó $H$, pertenecerá a la cola de la distribución, por lo que basta con devolver una variante de la cola normal mediante el método de Marsaglia o el método de la cola general de Marsaglia y Tsang.\\
		
	La elección del valor de $b$ no es crítica, pero elegir un valor de $b$ demasiado grande implica que habrá solapamiento al realizar el giro y desplazamiento descrito, mientras que si el valor de $b$ es demasiado pequeño, será necesario realizar frecuentemente el método para hallar los valores de la cola.
	En caso de utilizar el método anterior para "ajustar" la sigmoide al rectángulo, la elección de $b=2.29$ es prácticamente la máxima posible \cite{monty-python}. \\
		
	En lugar de una rotación y un desplazamiento de la región exterior al rectángulo, "estirar" la región $H$ permite un ajuste mejor, manteniendo constante el área de la sigmoide, y por tanto siendo este un método más complejo pero más eficiente para realizar dicha aproximación. 
	
	Definiendo el factor de estiramiento $s$ y la función de densidad de la región $H$, $f_H(x)$, 
	$$s=\dfrac{a}{b-a} \hspace{1.5cm} f_H(x)=f(x)-\dfrac{1}{b} \hspace{2mm} \text{con} \hspace{2mm} 0<x<a $$
	se tiene que la región $H$ girada y estirada tiene una función de densidad $f_{H'}(x)$.
	$$ f_{H'}(x) = \dfrac{1}{b} - s  \left[ f(s (b-x) ) -\dfrac{1}{b} \right] $$ 
	La siguiente figura representa gráficamente las transformaciones matemáticas descritas compuestas con la rotación aplicada a la sección $H$. 
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{include/stretching_sigmoid.png}
		\caption{Descripción gráfica del estiramiento descrito. \cite{monty-python}}
	\end{figure}
	
	Para este segundo caso, la elección habitual para el valor de $b$ es $b= \sqrt{2\pi}$. Esta elección no es crítica, cualquier valor entre $2.506$ y $2.5074$ es válido \cite{monty-python}, pero el par $b=\sqrt{2\pi}$, $a = \sqrt{\ln 4}$ son opciones fácilmente identificables con una precisión ilimitada.
	
	
\newpage
	\subsection{Comparación de métodos}
	A continuación, se compararán diferentes métodos para la generación de valores de la normal con el método Monty Python. Para ello, nos basaremos en la publicación citada \cite{comparacion-metodos}. Teniendo en cuenta que tanto el método generador de las secciones $F$, $G$ y $H$, como el método generador de las colas de la sigmoide son relevantes, el artículo divide la evaluación en cuatro secciones.

	
	\begin{itemize}

		\item Tests de bondad de ajuste. Para evaluar los algoritmos utilizados, se utiliza el test $\chi^{2}$. El número de intervalos en los que se divide la distribución para realizar el test es $k$, que se define mediante la siguiente expresión, siendo $n$ el número de muestras.

		\vspace{-5mm}
		$$k = \lceil n^{3/5} \rceil $$
		
		\item Test para valores altos de sigma. Este test mide principalmente el comportamiento de los generadores en las colas de la distribución. El principal reto es la baja probabilidad de obtener muestras que se encuentren en las colas. Se utiliza por tanto un algoritmo para "forzar" la generación de muestras que sean grandes múltiplos de sigma. 

		
		\item Test de aleatoriedad. Para este test, se utiliza la batería Crush, que forma parte de los \textit{TestU01}.

		
		\item Test de correlación interbloque. Este test mide como afecta la distribución de cada una de las muestras a la muestra siguiente, considerándose un buen resultado si la distribución de cada una de las muestras es independiente de las anteriores.

	\end{itemize}

	
	También se evalúa el número de operaciones realizadas y la velocidad de ejecución. 
	
	\subsubsection{Resultados en velocidad.}
	La velocidad se mide relativa a la velocidad del método de Rechazo Polar. El método Monty Python es el cuarto más rápido en comparación con los $16$ otros métodos de generación de variables aleatorias estudiados \cite{comparacion-metodos}, siendo $1.61$ veces más rápido que el método de Rechazo Polar. Cabe destacar que el número de operaciones realizadas es bajo en comparación con el método Wallace, que está por encima del método Monty Python en rapidez. Este último tiene menos cantidad de constantes que el método Ziggurat, que está también por encima del Monty Python en cuestión de velocidad.
	
	\begin{table}[H]
		\centering
		\begin{tabular}{|c||c|}
			\hline
			Nombre del método     & Velocidad     \\ \hline \hline
			Wallace (qual=1)      & 6.41          \\ \hline
			Ziggurat              & 4.29          \\ \hline
			Wallace (qual=4)      & 2.48          \\ \hline
			\textbf{Monty Python} & \textbf{1.61} \\ \hline
			PPND7                 & 1.16          \\ \hline
			Mixture-of-triangles  & 1.14          \\ \hline
			Polar                 & 1.00          \\ \hline   
		\end{tabular}
	\end{table}
	
	\subsubsection{Resultados en el test de bondad de ajuste $\chi^{2}$.}
	En el test de bondad de ajuste $\chi^{2}$, el método Monty Python no pasa el test al utilizar muestras de valores mayores a $2^{34}$. De nuevo, los métodos Wallace y Ziggurat obtienen mejores resultados, ya que no fallan al utilizar muestras de valor igual o mayor a $2^{36}$. El algoritmo PPND7 falla en la misma prueba que el método Monty Python, que a su vez es $3$ veces más lento.
	
	\subsubsection{Resultados en el test de valores altos de sigma.}
	Los resultados de este test muestran el múltiplo más alto de sigma donde el test se realiza con éxito. El método Monty Python obtiene un valor de $8.27$, siendo en este caso mejor que los métodos Ziggurat y Wallace. En comparación con el resto de generadores, el método Monty Python obtiene muy buenos resultados, situándose el cuarto mejor de todos los generadores comparados.
	
	\subsubsection{Resultados del test de aleatoriedad}

	El generador Monty Python no tuvo fallos al realizarse el test Crush.
	
	\subsubsection{Resultados del test de correlación interbloque.}
	Este test solo se realizó en los generadores Ziggurat, Wallace y Monty Pythhon, dado que fueron los más rápidos y en este test se necesitan realizar pruebas con muestras muy grandes. Los generadores de Ziggurat y Monty Python pasaron todos los tests con éxito, mientras que el generador Wallace (tanto el de baja calidad como el de alta), falló con un número inferior a $8$ iteraciones. Esto se debe a que el método Wallace es recursivo.
	
	\subsubsection{Conclusiones}
	Si bien es cierto que el método Wallace es el más rápido, presenta desventajas evidentes como la correlación. 
	El método Ziggurat, que es más lento que el Wallace, no tiene problemas de correlación, pero si que falla en el test Crush con una colisión identificada en los tests de doble precisión. 
	Además, utiliza un total de $388$ constantes, lo que puede ser problemático en algunos entornos. 
	El método Monty Python es el tercero más rápido después del Wallace y el Ziggurat, y presenta ventajas evidentes, como los buenos resultados en los tests de aleatoriedad y correlación, así como el bajo número de operaciones y constantes necesarias. 
	La mayor limitación del método Monty Python está en el uso de muestras cuya $n$ sea mayor que $2^{36}$. 
	
	
	\newpage

	\section{Simulación de sucesos discretos y optimización}

	\subsection{Enunciado}
	Consideremos un almacén de dos productos cuyos precios de venta al público son de $2.5$ y $3.5$ euros la unidad, respectivamente. La llegada de clientes al almacén se distribuye según un proceso de Poisson de parámetro $\lambda = 1.5$ clientes por hora y la cantidad de productos demandados por cada uno de ellos tiene la siguiente distribución:

	\begin{table}[H]
		\centering
		\begin{tabular}{|l||c|c|c|c|}
			\hline
			Demanda    & 1 unidad & 2 unidades & 3 unidades & 4 unidades \\ \hline \hline
			Producto 1 & 0.3      & 0.4        & 0.2        & 0.1        \\ \hline
			Producto 2 & 0.2      & 0.2        & 0.4        & 0.2        \\ \hline
		\end{tabular}
	\end{table}
	
	Para satisfacer la demanda de sus clientes el dueño del almacén mantiene un stock de productos. La política de pedidos al distribuidor es periódica, es decir todos los viernes a primera hora realiza un pedido, tomando como referencia el nivel de inventario de los productos en ese. Para satisfacer la demanda de sus clientes el dueño del almacén mantiene un stock de productos. La política de pedidos al distribuidor es periódica, es decir todos los viernes a primera hora realiza un pedido en el que tomando como referencia el nivel de inventario de los productos en ese momento, se solicitan las unidades necesarias para que el nivel del inventario de cada producto llegue a $1000$ y $1500$ unidades, respectivamente en cada producto.

	Asociado a cada pedido que realizamos al proveedor existe un coste fijo (coste de preparación) de $100$ euros, independientemente de las unidades demandadas. Adicionalmente, el coste por unidad incluida en el pedido depende de la cantidad solicitada habiendo descuentos por cantidad. Si el número de unidades demandadas del primer producto es menor o igual a $600$ el precio es de $1$ euro la unidad, mientras que si se piden más de $600$ el precio desciende a $75$ céntimos. Para el segundo producto, si el número de unidades demandadas es menor que $800$ el precio es de $1.5$ euros la unidad, mientras que si se piden más de $800$ el precio desciende a $1.25$ euros.

	El tiempo que tarda en ser servido el pedido por los proveedores (tiempo líder), sigue una distribución normal de media 48 horas y desviación típica $3.5$, pagándose en ese momento.

	Se ha llegado a un acuerdo con el proveedor de forma que, tomando como referencia las $48$ horas que tarda en media un pedido en ser servido, si el pedido llega con $3$ horas de retraso en la entrega del mismo se realiza un descuento del $0.03\%$ del valor del pedido, encareciéndose en la misma cantidad en el caso de que el pedido llegue con al menos $3$ horas de adelanto.
	
	El dueño del almacén debe pagar $0.0002$ euros por unidad del producto y unidad de tiempo, asociado al almacenamiento físico de los productos (alquiler del local, refrigeración...). En el caso de que al llegar un cliente éste solicite una cantidad mayor que la que hay en inventario, se le sirve lo que queda, perdiendo la venta restante.
	
	\begin{enumerate}
		\item[a)] Simular el comportamiento de almacén durante un periodo de tiempo de $5$ meses para estimar el beneficio esperado, la proporción de clientes cuya demanda se satisface completamente y el porcentaje de tiempo que el nivel del inventario permanece a cero. Para ello, supondremos que el nivel del inventario inicial es de $70$ unidades de ambos productos.

		\item[b)] Representar gráficamente la evolución del nivel del inventario durante los $5$ meses y durante los $5$ primeros días. 

		\item[c)] Mediante el uso de la metaheurística recocido simulado identificar cuál será la política de pedidos óptima, es decir, identificar cada cuánto tiempo se deberían realizar los pedidos y el valor de referencia del inventario para identificar el número de unidades a solicitar en la política de pedidos periódica.
	\end{enumerate}
	
	\textbf{Nota.} El almacén permanece abierto las $24$ horas al día de lunes a domingo. El proveedor y la empresa transportista (que sirve los pedidos) también trabajan las $24$ horas, no cerrando en ningún momento.

	\subsection{Modelización del problema}
	El problema descrito se puede representar según el diagrama a continuación.
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{include/modelo_almacen.png}
		\caption{Representación gráfica del modelado del problema}
	\end{figure}
	
	\hl{explicar la imagen con palabras}\newpage
	
	\subsection{Simulación del problema. Estimación de beneficios y satisfacción de clientes.}
	Según lo indicado en el apartado a), el objetivo de esta sección es obtener los siguientes valores.
	\begin{itemize}
		\item Estimación el beneficio esperado.
		\item Proporción de clientes cuya demanda se satisface completamente.
		\item Porcentaje de tiempo que el nivel del inventario permanece a cero.
	\end{itemize}
	Se simulará el comportamiento del sistema durante $5$ meses, teniendo inicialmente $70$ unidades de ambos productos en el almacén.
	 	
	\subsubsection{Implementación}
	La implementación de esta simulación se realizó utilizando el lenguaje python, definiendo de manera separada las rutinas de llegada de un cliente, llegada de un pedido y compra de un pedido.
	
	Cabe resaltar que un cliente no se considera satisfecho si recibe el pedido deseado de uno de los productos, pero no del otro.
	
	\subsubsection{Resultados}
	En esta sección se muestran los resultados de la ejecución de la simulación descrita. Tal y como
	se ha descrito en la sección de implementación del código, se ha llevado un seguimiento de la
	simulación gracias a las sentencias \textit{print()} que se han colocado en las distintas funciones del script.
Ejemplos de las salidas para cada uno de los eventos posibles son:
	\begin{itemize}
		\item \textbf{Llegada de un cliente.} Podemos hacer un seguimiento del momento en el que se produce
la llegada del cliente, cuántas unidades demanda de cada producto y el estado del almacén
antes y después del servicio.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.75\textwidth]{include/llegada_cliente.png}
		\end{figure}
		
		\item \textbf{Realización de un pedido.} Se muestra el instante de tiempo en el que se realiza el pedido,
el estado del almacén en ese momento y el tiempo que tardará en llegar dicho pedido.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.75\textwidth]{include/realizacion_pedido.png}
		\end{figure}
	
		\item \textbf{Llegada del pedido.} Se indica el instante en el que llega el pedido, el nivel de inventario
 antes y después de la llegada del pedido, y el tiempo que el almacén estuvo vacío en caso
de haber sido así.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.75\textwidth]{include/llegada_pedido.png}
		\end{figure}
		
	\end{itemize}

	En la siguiente gráfica podemos ver la evolución de los niveles de inventario de los productos $1$
y $2$ a lo largo del tiempo de simulación ($5$ meses), equivalente a $3600$ horas. Podemos
observar cómo se repite para cada tipo de producto la estructura de picos a lo largo del tiempo
con unas alturas variables pero muy cercanas.
	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{include/simulacion_5m_ancha.png}
	\end{figure}

	\begin{itemize}
		\item Durante el tiempo de simulación el total de ingresos recibidos gracias a las compras de
	los clientes es de $99\hspace{1mm}460$ euros.

		\item En total se han realizado $21$ pedidos que suman un gasto de $40\hspace{1mm}315.34$ euros.

		\item El coste de almacenamiento de los productos ha sido de $864.34$ euros.
	\end{itemize}

	Para calcular el beneficio obtenido basta con restar a los ingresos los gastos de pedido y los gastos
de almacenamiento:

	$$beneficio = 99\hspace{1mm}460 - 40\hspace{1mm}315.34 - 864.34 = 58\hspace{1mm}280.32$$
	
	
	Partiendo de un nivel de inventario de $70$ unidades de cada tipo de producto, y con la política de
pedidos descrita en el enunciado, la proporción de tiempo que el almacén está completamente
vacío es de un $5.33\%$ del tiempo, lo que en horas equivale a $191.3$ horas.

	
	En $3\hspace{1mm}600$ horas han llegado un total de $7\hspace{1mm}298$ clientes de los cuales:
	
	\begin{itemize}
		\item $6\hspace{1mm}941$ clientes su demanda ha sido completamente satisfecha.
		\item $357$ clientes su demanda no ha sido satisfecha.
	\end{itemize}

	Eso supone que la demanda de un $95.11\%$ de los clientes que llegaron a la tienda en este periodo

	de $5$ meses fue totalmente satisfecha.
	
	Analizando los resultados, si observamos más de cerca en la gráfica el periodo de tiempo que
comprende los $5$ primeros días de la simulación ($120$ horas), podemos observar que debido al
nivel inicial de inventario y a que la política de pedidos establece que los pedidos se hacen de
forma periódica cada $168$ horas (cada $7$ días), hay una gran franja en la que el inventario de ambos
productos está a $0$ sin poder satisfacerse la demanda de los clientes que llegan en ese periodo.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.75\textwidth]{include/simulacion_5d.png}
	\end{figure}
	
	Como se observa, partiendo únicamente con $70$ unidades de cada producto, alrededor de las $16$
	horas se agotaron las unidades del producto $2$ y a las $22$ horas de simulación ya se habían acabado
las existencias de ambos productos quedando completamente vacío el inventario, teniendo que	esperar a que se realizara el pedido y a que este llegara.
	
	\subsubsection{Representación gráfica de los resultados}
	
	
	\subsection{Simulación del problema con metaheurísticas. Identificación de política de pedidos óptima.}
	\subsubsection{Introducción al Recocido Simulado}
	Debido a la complejidad de los problemas de optimización que se busca resolver en el mundo, la búsqueda local y los métodos clásicos de optimización
	no son lo suficientemente buenos para acoplarse al gran número de factores de decisión y restricciones. Es por ello que se desarrollan las metaheurísticas,
	dando un paso más alla de las clásicas heurísticas que se centraban únicamente en un tipo de problema, y podían quedarse atrapadas en un mínimo local.
	//
	Las metaheurísticas	utilizan conocimiento de distintas areas de la ciencia, como puede ser la inteligencia artificial, la estadística, la genética... para proponer algoritmos que 
	devuelven una solución eficiente y satisfacctoria de un problema de optimización.//
	En esta práctica, se nos ha propuesto utilizar la metaheurística del tipo de Búsqueda Global, conocida como Recocido Simulado. Esta metaheurística se basa
	en el fénomeno de enfriamiento de metales que se estudia en el ámbito de metalurgia y termodinámica. //
	Para aplicar esta idea a un problema de optimización, se plantean tres principales etapas:
	\begin{itemize}
		\item En la primera etapa, las soluciones elegidas del entorno E(x) de manera aleatoria, no tienen porque ser las mejores. Si la solución
		es mejor que la anterior, cambiamos a esa directamente, pero si es peor, podemos cambiar a ella si la probabilidad supera un umbral determinado por
		una variable aleatoria. En esta primera fase, la probabilidad de elegir soluciones peores es más alta, evitando así caer en mínimos locales.
		\item En la segunda etapa, la probabilidad de que elijamos una peor solución ya no es tan grande, pero aun así hay posibilidad de volver atrás.
		\item En esta última etapa, solo aceptaremos movimientos que mejoren la solución actual.
	\end{itemize}
	
	En este algorimto es muy importante la elección del parámetro Temperatura. Este parámetro, ira decreciendo cada L iteraciones, hasta
	llegar a una temperatura final u otro punto de parada que se haya especificado. La forma en la que la temperatura influye en la búsqueda del algoritmo es mediante
	la expresión que define la distribución de Boltzman. 
	
	Esta es la distribución que va a tomar la probabilidad de elegir una peor solución, de manera que  si la temperatura es muy alta, la probabilidad de que elijamos una peor solución será mayor.
	La temperatura decrece según la siguiente expresión: 

	El valor alfa va a determinar cuanto disminuye la temperatura.//
	En general, los hiperparametros que vamos a tener que controlar para la ejecución del algorimto son los siguientes:
	\begin{itemize}
		\item Temperatura inicial
		\item L iteraciones que deben pasar para actualizar la temperatura
		\item alfa
		\item Criterio de parada
		\item El radio del entorno para elegir una solución vecina
	\end{itemize}
	
	El problema que buscamos resolver en esta práctica con este algorimto es encontrar el valor de periodicidad con el que se deben realaizar los pedidos,
	así como la cantidad que se debe pedir de cada uno de los productos para maximizar el beneficio. 
	\subsubsection{Implementación}
	Para implementar en python el recocido simulado, hemos definido el método \texttt{recocido$_$simulado}, que toma como parámetro un estado inicial, con las variables de 
	decisión inicializadas. A continuación, se inicializan las variables L, Temperatura Inicial, Temperatura final, alpha, Temperatura Final, el contador de iteraciones totales y el contador de pasos para cambiar la temperatura. 

	En la primera iteracion, damos a la variable \texttt{current$_$state}, que va a ir guardando el estado donde nos encontramos, el valor del estado inicial.
	Generamos los beneficios utilizando el método \texttt{get$_$benef}, que ejecuta la simulación desarrollada en el primer apartado, y los guardamos en la clave
	"benef" del current_state. Igualamos la variable \texttt{best$_$state} al current_state.\\

	Una vez finalizada esta primera iteración, entramos en un bucle que terminará cuando la temperatura alcance el valor mínimo. Este criterio de parada es uno
	de los más utilizados (referencia a tfm), si bien es cierto que existen otros.\\

	Al entrar en el bucle, utilizamos el método \texttt{get$_$neighbors} para obtener una solucion del entorno del estado actual, y de nuevo utilizando el método
	\texttt{get$_$benef}, obtenemos el beneficio que genera el vecino, y igualamos prob al valor de la probabilidad siguiendo la distribución de Boltzmann para la temperatura actual. Si la solución es mejor, entonces la variable \texttt{current$_$state} pasa a ser el estado del vecino.
	Si la solución es peor, entonces generamos una probabilidad aleatoria utlizando el generador \texttt{random.uniform}. Si su valor es mayor que la probabilidad inicializada previamente,
	entonces nos quedamos con el \texttt{current$_$state} actual. Si es menor, entonces acutalziamos current_state al valor del vecino.\\

	Dentro del mismo bucle, una vez se ha hecho el cambio de estado, se pasan por dos condicionales. En primer lugar, si el contador de pasos ha llegado al valor L, entonces
	actualizamos la temperatura. En segundo lugar, si la solución almacenada en \texttt{best$_$state} es peor que la del estado actual, actualizamos \texttt{best$_$state}.
	Esta modificación la hemos añadido para evitar que el algoritmo haya pasado en las primeras iteraciones por el mínimo global, y al rectificar haya terminado en un mínimo local.\\

	Cuando se alcanza la temperatura mínima, el algoritmo se detiene y el método devuelve el \texttt{best$_$state}.

	
	\subsubsection{Resultados}
	Los mejores resultados se han obtenido al inicializar los hiperparametros identificados previamente a los siguientes valores:
	\begin{itemize}
		\item La temperatura incial es de 10000 grados. Probando con valores menores, como 9000, no se alcanzaba el mínimo global.
		\item La temperatura final es de 0.1 grados
		\item Alpha es 0.95, siguiendo las recomendaciones.
		\item El valor de L es de 10 pasos
		\item El radio del entorno es igual a 1.
	\end{itemize}
	Para estos hiperparametros, hemos conseguido un beneficio de 59306.655€, 4291,35€ unidades mayor que el del estado inicial. Cabe destacar que, 
	al inspeccionar los logs que hemos impreso, el mínimo global se alcanza 150 iteraciones antes del final. Hemos probado a optimizar este
	resultado alterando el valor de L y la temperatura final, pero ninguna de las dos modificaciones ha dado resultados satisfactorios. A continuación,
	hemos probado a cambiar la distribución que usamos para obtener vecinos del entorno. Para elegir los vecinos, hemos optado por una normal de radio 1, ya que 
	al probar con distribuciones uniformes y mayor radio, el algoritmo se quedaba atrapado en minimos locales.
	
\newpage
	\section*{Bibliografía}
	\addcontentsline{toc}{section}{Bibliografía}
	\bibliography{include/references}
	\bibliographystyle{IEEEtran}
	
\end{document}